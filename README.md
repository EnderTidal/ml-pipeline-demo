# Build an ML Pipeline for Short-Term Rental Prices in NYC

**Udacity Machine Learning DevOps Engineer Nanodegree - Project Submission**

---

## ğŸ”— Project Links (Required for Submission)

**GitHub Repository:** https://github.com/EnderTidal/ml-pipeline-demo

**W&B Project (Public):** https://wandb.ai/jtibb15-western-governors-university/nyc_airbnb

**GitHub Releases:**
- v1.0.0: https://github.com/EnderTidal/ml-pipeline-demo/releases/tag/v1.0.0
- v1.0.1: https://github.com/EnderTidal/ml-pipeline-demo/releases/tag/v1.0.1

---

## ğŸ“‹ Project Overview

This project implements a complete end-to-end machine learning pipeline for predicting short-term rental prices in NYC using Airbnb data. The pipeline is designed to be reusable, reproducible, and production-ready.

### Key Features

- âœ… **Complete MLflow Pipeline** with 6 orchestrated steps
- âœ… **Weights & Biases Integration** for experiment tracking
- âœ… **Automated Data Validation** with pytest
- âœ… **Random Forest Model** with RÂ² = 0.564, MAE = $33.85
- âœ… **Production-Ready Code** with proper documentation
- âœ… **GitHub Releases** for version control (v1.0.0, v1.0.1)
- âœ… **Reproducible Environments** with conda

---

## ğŸ¯ Project Results

### Model Performance

| Dataset | RÂ² Score | MAE | Status |
|---------|----------|-----|--------|
| Sample 1 (Test) | 0.564 | $33.85 | âœ… All tests passed |
| Sample 2 (v1.0.1) | 0.580 | $32.42 | âœ… All tests passed |

### Pipeline Steps

1. **Download** - Retrieve sample data from W&B
2. **Basic Cleaning** - Remove outliers and filter boundaries
3. **Data Check** - Validate data quality with 6 automated tests
4. **Data Split** - Create train/validation/test sets
5. **Train Random Forest** - Train model with configurable hyperparameters
6. **Test Model** - Validate production model on test set

---

## ğŸš€ Quick Start

### Prerequisites

- **Operating System:** Ubuntu 22.04/24.04 or macOS
- **Python:** 3.13
- **Conda:** Installed and configured
- **W&B Account:** Free account at https://wandb.ai

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/EnderTidal/ml-pipeline-demo.git
cd ml-pipeline-demo
```

2. **Create conda environment:**
```bash
conda env create -f environment.yml
conda activate nyc_airbnb_dev
```

3. **Login to W&B:**
```bash
wandb login [your API key]
```

### Running the Pipeline

**Run all steps:**
```bash
mlflow run . -P steps=all
```

**Run specific steps:**
```bash
mlflow run . -P steps=download,basic_cleaning
```

**Run with custom parameters:**
```bash
mlflow run . \
  -P steps=train_random_forest \
  -P hydra_options="modeling.random_forest.n_estimators=200"
```

**Run from GitHub release:**
```bash
mlflow run https://github.com/EnderTidal/ml-pipeline-demo.git \
  -v v1.0.1 \
  -P hydra_options="etl.sample='sample2.csv'"
```

---

## ğŸ“ Project Structure

```
ml-pipeline-demo/
â”œâ”€â”€ components/              # Reusable pipeline components
â”‚   â”œâ”€â”€ get_data/           # Data download component
â”‚   â”œâ”€â”€ test_regression_model/  # Model testing component
â”‚   â””â”€â”€ train_val_test_split/   # Data splitting component
â”œâ”€â”€ src/                    # Project-specific steps
â”‚   â”œâ”€â”€ basic_cleaning/     # Data cleaning step
â”‚   â”œâ”€â”€ data_check/         # Data validation step
â”‚   â””â”€â”€ train_random_forest/    # Model training step
â”œâ”€â”€ main.py                 # Pipeline orchestration
â”œâ”€â”€ config.yaml             # Pipeline configuration
â”œâ”€â”€ environment.yml         # Conda environment
â”œâ”€â”€ MLproject              # MLflow project definition
â””â”€â”€ README.md              # This file
```

---

## ğŸ’» Implementation Details

### Data Cleaning (`src/basic_cleaning/run.py`)

- Removes price outliers (min: $10, max: $350)
- Filters properties to NYC boundaries
- Converts dates to datetime format
- Handles missing values

**Key Code:**
```python
# Price filtering
idx = df['price'].between(args.min_price, args.max_price)
df = df[idx].copy()

# Geographic filtering (v1.0.1)
idx = df['longitude'].between(-74.25, -73.50) & df['latitude'].between(40.5, 41.2)
df = df[idx].copy()
```

### Data Testing (`src/data_check/test_data.py`)

Implements 6 automated tests:
1. Column names validation
2. Neighborhood names validation
3. Geographic boundaries check
4. Neighborhood distribution similarity
5. Row count validation (15K-1M rows)
6. Price range validation

**Key Tests:**
```python
def test_row_count(data: pd.DataFrame) -> None:
    """Test if the dataset has a reasonable number of rows."""
    assert 15000 < data.shape[0] < 1000000

def test_price_range(data: pd.DataFrame, min_price: float, max_price: float) -> None:
    """Test if all prices are within the expected range."""
    assert data['price'].between(min_price, max_price).all()
```

### Model Training (`src/train_random_forest/run.py`)

- Preprocessing pipeline with SimpleImputer and OneHotEncoder
- Random Forest Regressor with configurable hyperparameters
- MLflow model logging and versioning
- Performance metrics (RÂ², MAE) tracking

**Key Pipeline:**
```python
# Preprocessing
non_ordinal_categorical_preproc = make_pipeline(
    SimpleImputer(strategy="most_frequent"),
    OneHotEncoder()
)

# Inference pipeline
sk_pipe = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("random_forest", random_forest)
    ]
)

# Training
sk_pipe.fit(X_train, y_train)

# Export
mlflow.sklearn.save_model(sk_pipe, "random_forest_dir")
```

---

## ğŸ”„ Release History

### v1.0.1 (Latest) - Bug Fix Release

**Changes:**
- Added latitude/longitude boundary filtering
- Fixes `test_proper_boundaries` test failure
- All tests now pass on sample2.csv

**Performance:**
- RÂ² Score: 0.580
- MAE: $32.42

### v1.0.0 - Initial Release

**Features:**
- Complete ML pipeline implementation
- Data cleaning and validation
- Random Forest model training
- Model testing and evaluation

**Performance:**
- RÂ² Score: 0.564
- MAE: $33.85

---

## ğŸ“Š W&B Artifacts

All pipeline artifacts are tracked in W&B:

- `sample.csv` - Raw data (raw_data)
- `clean_sample.csv` - Cleaned data (clean_sample) with 'reference' alias
- `trainval_data.csv` - Training/validation set (trainval_data)
- `test_data.csv` - Test set (test_data)
- `random_forest_export` - Trained model (model) with 'prod' alias

**View in W&B:** https://wandb.ai/jtibb15-western-governors-university/nyc_airbnb/artifacts

---

## ğŸ§ª Testing

### Run Data Validation Tests

```bash
mlflow run . -P steps=data_check
```

### Expected Test Results

All 6 tests should pass:
- âœ… test_column_names
- âœ… test_neighborhood_names
- âœ… test_proper_boundaries
- âœ… test_similar_neigh_distrib
- âœ… test_row_count
- âœ… test_price_range

---

## ğŸ“ MLOps Best Practices

This project demonstrates:

- **Experiment Tracking:** W&B for metrics and artifacts
- **Pipeline Orchestration:** MLflow for step coordination
- **Configuration Management:** Hydra for parameter control
- **Data Validation:** pytest for automated testing
- **Version Control:** Git/GitHub with semantic versioning
- **Reproducibility:** Conda environments and fixed seeds
- **Documentation:** Comprehensive code comments and README
- **Modularity:** Reusable components and clear interfaces

---

## ğŸ“ Configuration

All parameters are defined in `config.yaml`:

```yaml
main:
  project_name: nyc_airbnb
  experiment_name: development
  
etl:
  sample: sample1.csv
  min_price: 10
  max_price: 350
  
modeling:
  test_size: 0.2
  val_size: 0.2
  random_seed: 42
  stratify_by: neighbourhood_group
  max_tfidf_features: 5
  
  random_forest:
    n_estimators: 100
    max_depth: 50
    min_samples_split: 4
    min_samples_leaf: 3
```

**No parameters are hardcoded** - all values come from configuration.

---

## ğŸ› Troubleshooting

### Clean MLflow Environments

If you encounter environment issues:

```bash
# List MLflow environments
conda info --envs | grep mlflow

# Remove all MLflow environments (use with caution!)
for e in $(conda info --envs | grep mlflow | cut -f1 -d" "); do 
  conda uninstall --name $e --all -y
done
```

### Common Issues

1. **Python Version:** Ensure Python 3.13 is installed
2. **Conda:** Make sure conda is properly initialized
3. **W&B Login:** Verify you're logged in with `wandb login`
4. **MLflow Version:** Check that mlflow and wandb versions match

---

## ğŸ“š Technologies Used

- **Python 3.13**
- **MLflow 3.3.2** - Pipeline orchestration
- **Weights & Biases 0.24.0** - Experiment tracking
- **Hydra** - Configuration management
- **Scikit-learn 1.8.0** - Machine learning
- **Pandas 2.3.3** - Data manipulation
- **Pytest 8.4.2** - Testing
- **Conda** - Environment management

---

## ğŸ¯ Rubric Compliance

This project meets all Udacity rubric requirements:

- âœ… W&B project is public with all artifacts
- âœ… Data cleaning with proper types and docstrings
- âœ… Data testing with 2 custom tests implemented
- âœ… Data splitting integration
- âœ… Random Forest training with complete pipeline
- âœ… Model testing on production model
- âœ… GitHub releases created (v1.0.0, v1.0.1)
- âœ… Pipeline tested on multiple data samples
- âœ… No hardcoded parameters
- âœ… Production-ready code quality

---

## ğŸ“ Submission Information

**Project:** Build an ML Pipeline for Short-Term Rental Prices in NYC  
**Course:** Udacity Machine Learning DevOps Engineer Nanodegree  
**Status:** Complete âœ…  
**Date:** February 9, 2026

**GitHub Repository:** https://github.com/EnderTidal/ml-pipeline-demo  
**W&B Project:** https://wandb.ai/jtibb15-western-governors-university/nyc_airbnb

---

## ğŸ“„ License

[License](LICENSE.txt)

---

## ğŸ™ Acknowledgments

- Udacity for the project starter kit
- W&B for experiment tracking platform
- MLflow community for pipeline orchestration tools
